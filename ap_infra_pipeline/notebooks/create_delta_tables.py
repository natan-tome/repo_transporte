# ðŸ“Œ Cria widgets para entrada de parÃ¢metros (se ainda nÃ£o existirem)
dbutils.widgets.text("CATALOG_NAME", "", "Catalog Name")       # ðŸ· Nome do catÃ¡logo
dbutils.widgets.text("SCHEMA_NAME", "", "Schema Name")  # ðŸ“‘ Schema alvo
dbutils.widgets.text("VOLUME_PATH", "", "Volume Path")  # ðŸ“¦ Caminho do volume

# ðŸ“¥ LÃª valores dos widgets (podem ser sobrescritos por parÃ¢metros externos)
catalog_name = dbutils.widgets.get("CATALOG_NAME")    # ðŸ”„ Valor padrÃ£o ou runtime
schema_path = dbutils.widgets.get("SCHEMA_NAME")      # ðŸ—º Caminho lÃ³gico do schema
volume_path = dbutils.widgets.get("VOLUME_PATH")      # ðŸ—„ LocalizaÃ§Ã£o fÃ­sica dos dados brutos

# Tabelas do Meltano (JSONL)
json_tables = [
    "PurchaseOrderDetail",
    "PurchaseOrderHeader",
    "SalesOrderDetail",
    "SalesOrderHeader"
]

# Tabelas do Embulk (Parquet)
parquet_tables = [
    "humanresources_department",
    "humanresources_employee",
    "humanresources_employeedepartmenthistory",
    "humanresources_employeepayhistory",
    "humanresources_jobcandidate",
    "humanresources_shift",
    "person_address",
    "person_addresstype",
    "person_businessentity",
    "person_businessentityaddress",
    "person_businessentitycontact",
    "person_contacttype",
    "person_countryregion",
    "person_emailaddress",
    "person_password",
    "person_person",
    "person_personphone",
    "person_phonenumbertype",
    "person_stateprovince",
    "production_billofmaterials",
    "production_culture",
    "production_document",
    "production_illustration",
    "production_location",
    "production_product",
    "production_productcategory",
    "production_productcosthistory",
    "production_productdescription",
    "production_productdocument",
    "production_productinventory",
    "production_productlistpricehistory",
    "production_productmodel",
    "production_productmodelillustration",
    "production_productmodelproductdescriptionculture",
    "production_productphoto",
    "production_productproductphoto",
    "production_productreview",
    "production_productsubcategory",
    "production_scrapreason",
    "production_transactionhistory",
    "production_transactionhistoryarchive",
    "production_unitmeasure",
    "production_workorder",
    "production_workorderrouting",
    "purchasing_productvendor",
    "purchasing_shipmethod",
    "purchasing_vendor",
    "sales_countryregioncurrency",
    "sales_creditcard",
    "sales_currency",
    "sales_currencyrate",
    "sales_customer",
    "sales_personcreditcard",
    "sales_salesorderheadersalesreason",
    "sales_salesperson",
    "sales_salespersonquotahistory",
    "sales_salesreason",
    "sales_salestaxrate",
    "sales_salesterritory",
    "sales_salesterritoryhistory",
    "sales_shoppingcartitem",
    "sales_specialoffer",
    "sales_specialofferproduct",
    "sales_store"
]

# JSONL -> Delta
for table in json_tables:
    path = f"{volume_path}/api_{table}.jsonl"
    delta = f"{catalog_name}.{schema_path}.api_{table.lower()}"
    print(f"â–¶ Criando tabela Delta: {delta}")
    df = spark.read.json(path)
    df.write.format("delta").mode("overwrite").saveAsTable(delta)

# Parquet -> Delta
for table in parquet_tables:
    path = f"{volume_path}/db_{table}.parquet"
    delta = f"{catalog_name}.{schema_path}.db_{table}"
    print(f"â–¶ Criando tabela Delta: {delta}")
    df = spark.read.parquet(path)
    df.write.format("delta").mode("overwrite").saveAsTable(delta)