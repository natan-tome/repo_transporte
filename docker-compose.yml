services:
  # ğŸ­ ServiÃ§o de extraÃ§Ã£o via Embulk (dados do SQL Server para Parquet)
  extracao_embulk:
    build:
      context: ./ap_extracao_embulk  # ğŸ“‚ DiretÃ³rio do Dockerfile
      dockerfile: Dockerfile         # ğŸ³ ConfiguraÃ§Ã£o de construÃ§Ã£o padrÃ£o
    container_name: ap_extracao_embulk  # ğŸ·ï¸ Nome fixo para fÃ¡cil referÃªncia
    volumes:
      - ./ap_extracao_embulk:/app    # ğŸ”„ Sync de cÃ³digo local-container
      - shared_data:/data            # ğŸ“¦ Dados compartilhados entre serviÃ§os
    env_file:
      - ./.env  # ğŸ”’ VariÃ¡veis sensÃ­veis (credenciais DB)
    working_dir: /app  # ğŸ“‚ DiretÃ³rio padrÃ£o para execuÃ§Ã£o de comandos
    entrypoint: ["sh", "-c", "while true; do sleep 3600; done"]  # â²ï¸ MantÃ©m container vivo para execuÃ§Ã£o manual

  # ğŸŒ ServiÃ§o de extraÃ§Ã£o via Meltano (API REST para JSONL)
  extracao_meltano:
    build:
      context: ./ap_extracao_meltano  # ğŸ“¦ Projeto Meltano completo
      dockerfile: Dockerfile          # ğŸ› ï¸ Build personalizado com dependÃªncias
    container_name: ap_extracao_meltano  # ğŸ·ï¸ IdentificaÃ§Ã£o clara no Docker
    volumes:
      - ./ap_extracao_meltano:/app    # ğŸ”„ Desenvolvimento em hot-reload
      - shared_data:/data             # ğŸ¤ Dados compartilhados com Embulk
    working_dir: /app  # ğŸ“‚ Ponto de partida para comandos meltano
    env_file:
      - ./.env  # ğŸ”§ ConfiguraÃ§Ãµes de ambiente (URLs, limites)
    entrypoint: ["sh", "-c", "while true; do sleep 3600; done"]  # â³ MantÃ©m container ativo para execuÃ§Ãµes sob demanda
  
  infra_pipeline:
    build:
      context: ./ap_infra_pipeline
      dockerfile: Dockerfile
    container_name: ap_infra_pipeline
    volumes:
      - ./ap_infra_pipeline:/infra            # CÃ³digo fonte
      - ./shared_data:/data    
      # - ./.env:/app/.env             # Dados compartilhados
      # - ./.env:/app/.env:ro               # <-- Monta o .env da pasta main na raiz do projeto como /app/.env (readonly)
      - ./ap_infra_pipeline/notebooks:/notebooks
    working_dir: /infra
    network_mode: "host"
    env_file:
      - ./.env                           # <-- Garante que as variÃ¡veis sejam carregadas do .env montado
    entrypoint: [ "sh", "-c", "while true; do sleep 3600; done" ]

  ingestao_databricks:
    build:
      context: ./ap_ingestao_databricks
    container_name: ap_ingestao_databricks
    working_dir: /app
    env_file:
      - ./.env
    volumes:
      - ./ap_ingestao_databricks:/app
      - shared_data:/data
    entrypoint: [ "sh", "-c", "while true; do sleep 3600; done" ]

  processamento_job:
    build:
      context: ./ap_processamento_job
    container_name: ap_processamento_job
    working_dir: /infra
    network_mode: "host"
    env_file:
      - ./.env
    volumes:
      - ./ap_processamento_job:/infra
      - shared_notebooks:/shared
      - ./.env:/env/.env:ro
    entrypoint: [ "sh", "-c", "while true; do sleep 3600; done" ]



# ğŸ“¦ Volume persistente para dados intermediÃ¡rios
volumes:
  shared_data:  # ğŸ—ƒï¸ Armazena Parquet/JSONL entre estÃ¡gios do pipeline
  shared_notebooks:
  
networks:
  default:
    driver: bridge

